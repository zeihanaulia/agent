# DeepAgent Tool Execution Investigation

**Date**: 2025-11-12
**Issue**: Phase 4 agent generates no code patches despite improvements

## Summary

After extensive investigation and iterative improvements, identified that the root cause is not architectural but **model capability/tool binding**:

1. ‚úÖ File list context is properly scanned and injected
2. ‚úÖ Timeout increased from 60s ‚Üí 180s (analysis) and 120s ‚Üí 240s (implementation)
3. ‚úÖ System prompt enhanced with REQUIRED WORKFLOW section
4. ‚úÖ Agent response captured properly with debug logging

**But**: Result shows `üìÅ Files dict size: 0` and agent attempts `edit_file with missing path` (skipped 3x)

## Root Cause Analysis

### What Works
- Phase 1-3 execute successfully
- Agent receives file context list (15 files scanned from springboot-demo)
- Agent timeout handling works (3.8-4.8 min execution)
- Result structure captured: `dict with keys: ['messages', 'todos', 'files']`

### What Fails  
- `files` dict is empty (size: 0)
- `messages` contain edit_file tool calls with empty paths
- Agent describes changes in text instead of executing tools:
  - "I updated the codebase to add explicit validation for supported payment methods"
  - "I updated InMemoryOrderRepository: now validates inputs..."
  
This indicates:
- Agent is not calling tools properly
- LLM (gpt-5-mini) may not recognize available tools
- Tool parameters not populated with file paths

### Key Observation

Agent response shows it ATTEMPTS edit_file but with empty `path` parameter:
```
‚ö†Ô∏è  Skipped edit_file with missing path (3x)
```

This means:
1. Agent knows about the tool (mentions it in messages)
2. But doesn't populate required parameters
3. Falls back to text description

## DeepAgent Documentation Findings

`create_deep_agent()` signature shows:
```python
"This agent will by default have access to a tool to write todos (write_todos),
six file editing tools: write_file, ls, read_file, edit_file, glob_search, grep_search"
```

So tools SHOULD be available. But LLM needs to:
1. Know what tools exist
2. Understand their signatures
3. Call them with proper parameters

## Model Capability Theory

Hypothesis: `gpt-5-mini` (likely gpt-4-mini or similar small model) has limitations:
- May not handle complex tool schemas well
- May not follow detailed parameter requirements
- May hallucinate tool calls without proper args

## Improvements Made in This Session

1. **Fix 2.1** ‚úÖ: System prompt with explicit "REQUIRED WORKFLOW" section
   - States "FIRST call read_file, THEN call edit_file"
   - Provides clear workflow steps
   - Emphasizes "NEVER empty parameters"

2. **Fix 2.3** ‚úÖ: Pre-loaded file list context
   - Scans codebase for 40 relevant files
   - Injects list into prompt: "AVAILABLE FILES IN CODEBASE:"
   - Tells agent "ONLY use files from the list above"

3. **Timeout Enhancement** ‚úÖ: Increased Phase 4 timeout
   - Step 1 (analysis): 60s ‚Üí 180s
   - Step 2 (implementation): 120s ‚Üí 240s

4. **Debug Logging** ‚úÖ: Added result structure visibility
   - Prints result type and keys
   - Shows files dict size
   - Enables tracking of extraction failures

## Next Steps (Not Implemented)

### Option 1: Try Stronger Model
- Replace `gpt-5-mini` with `gpt-4` or `claude-opus`
- May have better tool calling capability
- Downside: Higher cost, slower execution

### Option 2: Explicit Tool Definitions
- Pass `tools` parameter to `create_deep_agent()`
- Define write_file, edit_file with detailed schemas
- Force LLM to see tool signatures explicitly

### Option 3: Tool Output Format
- Instead of tools, ask LLM to output JSON/YAML patches
- Parse output and apply patches directly
- Bypass tool calling mechanism

### Option 4: Constraint-based Planning
- In Phase 4 prompt, ask agent to output a PLAN first
- Require: "For each file: [1] path [2] operation [3] old text [4] new text"
- Then execute from plan template

## Files Modified

- `/agent/scripts/coding_agent/agents/agent_factory.py`: Enhanced system prompt
- `/agent/scripts/coding_agent/flow_synthesize_code.py`: 
  - Timeout: 60‚Üí180s, 120‚Üí240s
  - Debug logging for result structure
  - Format 6 handler for direct-files (already existed)

## Test Results

**Latest Test**: Create Voucher System (3.8m execution)
```
Files Affected: 1
New Files: 3 (planned, not created)
Execution Status: no_patches
Time: 310.48s

Result:
- üìÅ Files dict size: 0 (empty)
- ‚ö†Ô∏è Skipped edit_file with missing path (3x)
- ‚ÑπÔ∏è No code patches generated
```

## Conclusion

The agent architecture and improvements are sound. The blocking issue is **LLM model capability in executing tools with proper parameters**, specifically:
- Not recognizing or calling available tools correctly
- Not populating tool parameters from available context

The issue is NOT:
- ‚ùå File scanning (works, 15 files found)
- ‚ùå Prompt clarity (enhanced significantly)  
- ‚ùå Timeout (increased, not hitting limit)
- ‚ùå Result extraction (properly logs all formats)
- ‚ùå DeepAgent configuration (documentation says tools are automatic)

The issue IS likely:
- ‚úÖ LLM (gpt-5-mini) capability with tool calling
- ‚úÖ Tool parameter binding in LangChain/DeepAgent layer
- ‚úÖ Model-specific tool schema interpretation

## Recommendation

**Immediate Action**: Test with stronger model (`gpt-4`) to confirm tool capability theory

**If successful with gpt-4**: Problem confirmed as model limitation, document as "requires capable model"

**If fails with gpt-4**: Problem is deeper in DeepAgent/LangChain tool binding layer, requires:
1. Review LangChain tool definition
2. Check DeepAgent middleware bindings
3. Consider explicit tool parameter passing
