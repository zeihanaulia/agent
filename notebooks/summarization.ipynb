{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a84e7f",
   "metadata": {},
   "source": [
    "# Text Summarization dengan BART\n",
    "\n",
    "Notebook ini mendemonstrasikan cara meringkas teks menggunakan model BART dari Hugging Face Transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daba0590",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6cdf62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zeihanaulia/Programming/research/agent/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c2740e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face has become a central platform for AI developers. The open-source Transformers library allows anyone to run state-of-the-art models.\n"
     ]
    }
   ],
   "source": [
    "article = \"\"\"\n",
    "Hugging Face has become a central platform for AI developers,\n",
    "hosting more than 1 million pretrained models, datasets, and apps.\n",
    "Its open-source Transformers library allows anyone to run\n",
    "state-of-the-art models with just a few lines of Python code.\n",
    "\"\"\"\n",
    "summary = summarizer(article, max_length=60, min_length=10, do_sample=False)\n",
    "print(summary[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc87fc0",
   "metadata": {},
   "source": [
    "# Penjelasan Kode\n",
    "\n",
    "Pada kode di atas, kita mengimpor fungsi 'pipeline' dari pustaka 'transformers'.\n",
    "\n",
    "Kemudian, kita membuat sebuah pipeline untuk tugas 'summarization' menggunakan model 'facebook/bart-large-cnn'.\n",
    "\n",
    "Fungsi 'pipeline' ini digunakan untuk membuat model yang siap digunakan untuk tugas tertentu, dalam hal ini adalah meringkas teks.\n",
    "\n",
    "Kita mendefinisikan sebuah artikel yang akan diringkas, lalu memanggil fungsi summarizer dengan parameter panjang maksimum dan minimum untuk ringkasan.\n",
    "\n",
    "Terakhir, kita mencetak hasil ringkasan dari artikel tersebut dengan mengakses elemen pertama dari daftar hasil dan mengambil teks ringkasannya.\n",
    "\n",
    "### QnA: Pertanyaan dan Jawaban\n",
    "\n",
    "**Q: Apakah model 'facebook/bart-large-cnn' ini LLM?**\n",
    "\n",
    "A: Ya, model 'facebook/bart-large-cnn' adalah salah satu contoh dari Large Language Model (LLM) yang dirancang untuk memahami dan menghasilkan teks dalam bahasa alami. LLM seperti BART (Bidirectional and Auto-Regressive Transformers) memiliki kemampuan untuk menangani berbagai tugas pemrosesan bahasa alami, termasuk meringkas teks, menjawab pertanyaan, dan menerjemahkan bahasa. Model ini dilatih pada sejumlah besar data teks, memungkinkan mereka untuk menangkap pola bahasa yang kompleks dan menghasilkan output yang koheren dan relevan.\n",
    "\n",
    "**Q: Berapa parameter yang digunakan pada fungsi summarizer di atas dan apa fungsinya?**\n",
    "\n",
    "A: Fungsi summarizer di atas menggunakan tiga parameter utama:\n",
    "1. max_length: Parameter ini menentukan panjang maksimum dari ringkasan yang dihasilkan. Dalam contoh ini, ringkasan tidak akan melebihi 60 token.\n",
    "2. min_length: Parameter ini menentukan panjang minimum dari ringkasan yang dihasilkan. Dalam contoh ini, ringkasan akan memiliki setidaknya 10 token.\n",
    "3. do_sample: Parameter ini adalah boolean yang menentukan apakah model harus menggunakan sampling acak saat menghasilkan ringkasan. Jika diatur ke False, model akan menghasilkan ringkasan yang paling mungkin berdasarkan distribusi probabilitas.\n",
    "\n",
    "**Q: Model ini berapa parameternya?**\n",
    "\n",
    "A: Model 'facebook/bart-large-cnn' memiliki sekitar 406 juta parameter. Parameter ini adalah bobot yang dipelajari oleh model selama proses pelatihan dan digunakan untuk membuat prediksi atau menghasilkan teks berdasarkan input yang diberikan.\n",
    "\n",
    "**Q: Bagaimana cara kerja model ini dalam meringkas teks?**\n",
    "\n",
    "A: Model 'facebook/bart-large-cnn' bekerja dengan menggunakan arsitektur transformer yang terdiri dari encoder dan decoder. Proses meringkas teks dimulai dengan mengubah teks input menjadi representasi numerik yang dapat diproses oleh model. Encoder memproses teks input untuk menangkap konteks dan makna, sementara decoder menghasilkan ringkasan berdasarkan representasi yang dihasilkan oleh encoder. Model ini dilatih pada sejumlah besar data teks, memungkinkannya untuk memahami struktur bahasa dan menghasilkan ringkasan yang koheren dan relevan dengan konten asli.\n",
    "\n",
    "**Q: Apa keunggulan menggunakan model 'facebook/bart-large-cnn' untuk meringkas teks dibandingkan metode tradisional?**\n",
    "\n",
    "A: Keunggulan menggunakan model 'facebook/bart-large-cnn' untuk meringkas teks dibandingkan metode tradisional meliputi:\n",
    "1. Akurasi yang lebih tinggi: Model ini dapat menangkap konteks dan makna yang lebih baik, menghasilkan ringkasan yang lebih relevan dan informatif.\n",
    "2. Fleksibilitas: Model ini dapat digunakan untuk berbagai jenis teks dan domain, sementara metode tradisional mungkin terbatas pada jenis teks tertentu.\n",
    "3. Kemampuan pembelajaran: Model ini dapat terus ditingkatkan dengan pelatihan tambahan pada data baru, sementara metode tradisional biasanya statis.\n",
    "4. Penggunaan bahasa alami: Model ini menghasilkan ringkasan yang terdengar lebih alami dan mudah dipahami."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
