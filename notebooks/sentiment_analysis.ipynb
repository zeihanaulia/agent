{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3068e2bc",
   "metadata": {},
   "source": [
    "# Sentiment Analysis dengan DistilBERT\n",
    "\n",
    "Notebook ini mendemonstrasikan analisis sentimen menggunakan model DistilBERT dari Hugging Face Transformers. Kita akan menganalisis sentimen dari teks dalam bahasa Indonesia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3433d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c3ee67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment = pipeline(\n",
    "    \"sentiment-analysis\", # type: ignore\n",
    "    model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ") # pyright: ignore[reportArgumentType, reportCallIssue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4a43448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998571872711182}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9997599720954895}]\n",
      "[{'label': 'POSITIVE', 'score': 0.688407838344574}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment(\"This movie so good enough!\"))\n",
    "print(sentiment(\"This movie so terrible!\"))\n",
    "print(sentiment(\"This movie is okay? not sure, story seems average. but acting not so weird. nice try.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7e0792",
   "metadata": {},
   "source": [
    "# Penjelasan Hasil Analisis\n",
    "- **\"This movie so good enough!\"**: Diprediksi sebagai POSITIVE dengan score tinggi (~0.9999), yang benar karena kata \"good\" menunjukkan positif.\n",
    "- **\"This movie so terrible!\"**: Diprediksi sebagai NEGATIVE dengan score tinggi (~0.9998), yang benar karena kata \"terrible\" menunjukkan negatif.\n",
    "- **\"This movie is okay? not sure, story seems average. but acting not so weird. nice try.\"**: Diprediksi sebagai POSITIVE dengan score sedang (~0.6884). Model menebak positif karena kata seperti \"nice try\" dan \"acting not so weird\" dianggap positif, meskipun teks ambigu dan netral secara keseluruhan. Score <0.7 menunjukkan ketidakyakinan model.\n",
    "\n",
    "Model ini akurat untuk teks Inggris sederhana, tapi kurang untuk bahasa lain seperti Indonesia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780ec419",
   "metadata": {},
   "source": [
    "### QnA: Pertanyaan dan Jawaban\n",
    "**Pertanyaan 1: Bagaimana cara kerjanya, gimana bisa mengetahui sentiment dari text?**\n",
    "\n",
    "Jawaban: Model sentiment analysis seperti DistilBERT bekerja dengan langkah-langkah berikut:\n",
    "1. **Tokenisasi**: Teks dipecah menjadi token (kata atau sub-kata) menggunakan tokenizer model.\n",
    "2. **Embedding**: Setiap token diubah menjadi vektor numerik (embedding) yang mewakili makna kata dalam konteks.\n",
    "3. **Proses Transformer**: Model menggunakan arsitektur Transformer untuk memahami hubungan antar token, fokus pada konteks keseluruhan teks.\n",
    "4. **Klasifikasi**: Output dari Transformer diproses oleh layer klasifikasi (biasanya softmax) untuk memprediksi label seperti POSITIVE atau NEGATIVE, dengan score probabilitas.\n",
    "5. **Pelatihan**: Model dilatih pada dataset berlabel (positif/negatif) untuk belajar pola sentiment dari jutaan contoh teks.\n",
    "\n",
    "Dengan cara ini, model \"belajar\" mengenali pola kata dan konteks yang menunjukkan sentimen positif atau negatif, tanpa aturan manual.\n",
    "\n",
    "**Pertanyaan 2: Bagaimana model bisa paham, sertakan paper dan penjelasan singkatnya?**\n",
    "\n",
    "Jawaban: Model DistilBERT adalah versi ringkas dari BERT (Bidirectional Encoder Representations from Transformers), yang belajar memahami bahasa melalui pre-training pada teks besar tanpa label, lalu fine-tuned untuk tugas spesifik seperti sentiment analysis.\n",
    "\n",
    "- **Pre-training**: Model dilatih untuk memprediksi kata yang hilang dalam kalimat (Masked Language Modeling) dan apakah dua kalimat berurutan (Next Sentence Prediction). Ini membuat model paham konteks kata dalam teks.\n",
    "- **Fine-tuning**: Untuk sentiment, model dilatih lagi pada dataset berlabel (seperti SST-2) untuk mengklasifikasikan teks sebagai positif/negatif.\n",
    "- **Arsitektur**: Menggunakan self-attention untuk fokus pada kata penting, memahami nuansa seperti sarkasme atau konteks.\n",
    "\n",
    "Referensi Paper:\n",
    "- **BERT**: \"[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\" oleh Jacob Devlin et al. (2018)](https://arxiv.org/abs/1810.04805). Paper ini memperkenalkan BERT, yang revolusioner karena memahami konteks dua arah (kiri-kanan dan kanan-kiri).\n",
    "- **DistilBERT**: \"[DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter\" oleh Victor Sanh et al. (2019)](https://arxiv.org/abs/1910.01108). Paper ini menjelaskan cara membuat BERT lebih efisien dengan distillation, mempertahankan akurasi sambil mengurangi ukuran.\n",
    "\n",
    "Model \"paham\" karena belajar pola statistik dari data besar, bukan aturan grammar manual. Untuk detail lebih lanjut, baca paper di arXiv atau Hugging Face docs.\n",
    "\n",
    "**Pertanyaan 3: Kalau hasil ambigu atau score tidak tinggi, gimana?**\n",
    "\n",
    "Jawaban: Jika score rendah (misalnya <0.7), model tidak yakin dengan prediksi. Ini bisa terjadi pada teks ambigu, netral, atau sarkastik. Contoh:\n",
    "- Teks \"This movie is okay\" mungkin score POSITIVE ~0.6, NEGATIVE ~0.4â€”model menebak positif tapi tidak yakin.\n",
    "- Solusi: Gunakan model dengan label netral (seperti `nlptown/bert-base-multilingual-uncased-sentiment` yang punya POSITIVE, NEGATIVE, NEUTRAL), atau analisis konteks manual. Score rendah menunjukkan teks tidak jelas sentimennya.\n",
    "\n",
    "### List Model untuk Eksperimen\n",
    "Coba ganti model di pipeline dengan salah satu dari list berikut untuk eksperimen sentiment analysis. Ganti `model=\"...\"` di cell pipeline:\n",
    "\n",
    "1. `distilbert-base-uncased-finetuned-sst-2-english` (default, untuk Inggris)\n",
    "2. `nlptown/bert-base-multilingual-uncased-sentiment` (multilingual, mendukung banyak bahasa termasuk Indonesia)\n",
    "3. `cardiffnlp/twitter-roberta-base-sentiment` (untuk teks sosial media seperti Twitter)\n",
    "4. `j-hartmann/emotion-english-distilroberta-base` (deteksi emosi: joy, sadness, dll.)\n",
    "5. `roberta-base` (RoBERTa base, perlu fine-tune manual)\n",
    "6. `bert-base-multilingual-uncased-sentiment` (multilingual BERT untuk sentiment)\n",
    "7. `xlnet-base-cased` (XLNet, alternatif Transformer)\n",
    "8. `albert-base-v2` (ALBERT, lebih efisien)\n",
    "9. `distilroberta-base` (DistilRoBERTa, ringkas)\n",
    "10. `facebook/bart-large-mnli` (BART untuk zero-shot classification, bisa adaptasi untuk sentiment)\n",
    "\n",
    "Coba ganti model atau teks untuk eksperimen!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
